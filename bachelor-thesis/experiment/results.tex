\subsection{Results} \label{results}
All the different configurations together are resulting in 46240 different simulations that have been executed. The
$Precision_{\mu}$ and $Recall_{\mu}$ of every simultaion has been computed and the result has been written to a
CSV\footnote{https://tools.ietf.org/html/rfc4180} file ordered by the $F_{1}score_{\mu}$. The file can be found at
GitHub\footnote{https://raw.githubusercontent.com/GordonLesti/SlidingWindowFilter/master/data/swf-result.csv}. Line one
to ten of that file are presented by table \ref{tab:result}.

\begin{table}[H]
    \begin{center}
        {\tiny
            \begin{tabular}{l l l l l l l l l}
                \textbf{distance} & \textbf{filter} & \textbf{window} & \textbf{threshold} & \textbf{precision} & \textbf{recall} & \textbf{f1score} & \textbf{accuracy} & \textbf{\#(nnc)}\\
                \hline
                NDTW SCB(0.12) & ACF(2.0) & Middle  & HalfAverageDistance & 0.8413 & 0.6545 & 0.7362 & 0.9886 & 4221\\
                NDTW SCB(0.12) & VF(1.9) & Middle  & HalfAverageDistance & 0.8406 & 0.6539 & 0.7356 & 0.9885 & 3330\\
                NDTW SCB(0.12) & VF(2.0) & Middle  & HalfAverageDistance & 0.8406 & 0.6539 & 0.7356 & 0.9885 & 3568\\
                NDTW SCB(0.12) & NoFilter & Middle  & HalfAverageDistance & 0.8406 & 0.6539 & 0.7356 & 0.9885 & 4893\\
                NDTW SCB(0.11) & ACF(2.0) & Middle  & HalfAverageDistance & 0.8292 & 0.6527 & 0.7304 & 0.9882 & 4211\\
                NDTW SCB(0.11) & NoFilter & Middle & HalfAverageDistance & 0.8292 & 0.6527 & 0.7304 & 0.9882 & 4883\\
                NDTW SCB(0.12) & VF(1.7) & Middle & HalfAverageDistance & 0.8398 & 0.6451 & 0.7297 & 0.9883 & 2989\\
                NDTW SCB(0.12) & VF(1.8) & Middle & HalfAverageDistance & 0.8398 & 0.6451 & 0.7297 & 0.9883 & 3134\\
                NDTW SCB(0.12) & CF(1.8) & Middle & HalfAverageDistance & 0.8398 & 0.6451 & 0.7297 & 0.9883 & 3699\\
                NDTW SCB(0.12) & CF(1.9) & Middle & HalfAverageDistance & 0.8398 & 0.6451 & 0.7297 & 0.9883 & 3786
            \end{tabular}
        }
    \end{center}
    \caption{The top ten simulations and their configurations measured on the $F_{1}score_{\mu}$ with rounded values.
    Column one to four are the configurations as described in section \ref{sliding_window_simulation}, column five to
    eight are the resulting performance measures as described in section \ref{performance_measure} and column nine are
    the number of calls to the Nearest Neighbour classification for every simulation.}
	\label{tab:result}
\end{table}

The produced data can be explored with different approaches. As table \ref{tab:result} shows exists a dominating subset
of configurations under the order of $F_{1}score_{\mu}$. Part of this dominating configuration are
\begin{itemize}
    \item \textbf{NDTW SCB(0.12):} DTW with normalization and a Sakoe-Chiba band of 24\% as described in
    \ref{sakoe-chiba_band}
    \item \textbf{Middle:} window size determination as described in \ref{window_size_determination}
    \item \textbf{Half Average Distance:} threshold determination as described in \ref{threshold_determination}
\end{itemize}
An evaluation on the average performance of a configuration appears not effective, since some options are depending on
each other. Hereinafter will be examined how the results are changing if a simulation differs from the dominating
configuration. The influence of the filter will be examined in the end. However, it should be mentioned that the
following results could have an other ranking under an other performance measure as figure \ref{fig:result} shows.

\begin{figure}
    \begin{center}
        \begin{tabular}{ccc}
            \resizebox {0.3\textwidth} {!} {
                \begin{tikzpicture}[spy using outlines={circle, magnification=6, connect spies}]
                    \begin{axis}[
                        xmin=0,
                        xmax=1,
                        ymin=0,
                        ymax=1,
                        width=\axisdefaultwidth,
                        height=\axisdefaultwidth,
                        xlabel=$Precision_{\mu}$,
                        ylabel=$Recall_{\mu}$,
                        samples=100]
                        \addplot[blue, only marks, mark size=0.4] table {../data/fig/result/f1score.dat};
                        \addplot[gray, domain=0.051:1] {(0.1 * x) / (2 * x - 0.1)};
                        \addplot[gray, domain=0.11:1] {(0.2 * x) / (2 * x - 0.2)};
                        \addplot[gray, domain=0.16:1] {(0.3 * x) / (2 * x - 0.3)};
                        \addplot[gray, domain=0.21:1] {(0.4 * x) / (2 * x - 0.4)};
                        \addplot[gray, domain=0.26:1] {(0.5 * x) / (2 * x - 0.5)};
                        \addplot[gray, domain=0.31:1] {(0.6 * x) / (2 * x - 0.6)};
                        \addplot[gray, domain=0.36:1] {(0.7 * x) / (2 * x - 0.7)};
                        \addplot[gray, domain=0.41:1] {(0.8 * x) / (2 * x - 0.8)};
                        \addplot[gray, domain=0.46:1] {(0.9 * x) / (2 * x - 0.9)};
                        \coordinate (spypoint) at (axis cs:0.841307095143528,0.654494382022472);
                        \coordinate (magnifyglass) at (axis cs:0.3,0.3);
                    \end{axis}
                    \spy [size=2.5cm] on (spypoint)
                        in node[fill=white] at (magnifyglass);
                \end{tikzpicture}
            } &
            \resizebox {0.3\textwidth} {!} {
                \begin{tikzpicture}[spy using outlines={circle, magnification=6, connect spies}]
                    \begin{axis}[
                        xmin=0,
                        xmax=1,
                        ymin=0,
                        ymax=1,
                        width=\axisdefaultwidth,
                        height=\axisdefaultwidth,
                        xlabel=$Precision_{\mu}$,
                        ylabel=$Recall_{\mu}$,
                        samples=100]
                        \addplot[red, only marks, mark size=0.4] table {../data/fig/result/f0.5score.dat};
                        \addplot[gray, domain=0.081:1] {(0.25 * 0.1 * x) / (1.25 * x - 0.1)};
                        \addplot[gray, domain=0.161:1] {(0.25 * 0.2 * x) / (1.25 * x - 0.2)};
                        \addplot[gray, domain=0.25:1] {(0.25 * 0.3 * x) / (1.25 * x - 0.3)};
                        \addplot[gray, domain=0.33:1] {(0.25 * 0.4 * x) / (1.25 * x - 0.4)};
                        \addplot[gray, domain=0.41:1] {(0.25 * 0.5 * x) / (1.25 * x - 0.5)};
                        \addplot[gray, domain=0.49:1] {(0.25 * 0.6 * x) / (1.25 * x - 0.6)};
                        \addplot[gray, domain=0.57:1] {(0.25 * 0.7 * x) / (1.25 * x - 0.7)};
                        \addplot[gray, domain=0.65:1] {(0.25 * 0.8 * x) / (1.25 * x - 0.8)};
                        \addplot[gray, domain=0.73:1] {(0.25 * 0.9 * x) / (1.25 * x - 0.9)};
                        \coordinate (spypoint) at (axis cs:0.8761578735,0.6110955056);
                        \coordinate (magnifyglass) at (axis cs:0.3,0.3);
                    \end{axis}
                    \spy [size=2.5cm] on (spypoint)
                        in node[fill=white] at (magnifyglass);
                \end{tikzpicture}
            } &
            \resizebox {0.3\textwidth} {!} {
                \begin{tikzpicture}[spy using outlines={circle, magnification=6, connect spies}]
                    \begin{axis}[
                        xmin=0,
                        xmax=1,
                        ymin=0,
                        ymax=1,
                        width=\axisdefaultwidth,
                        height=\axisdefaultwidth,
                        xlabel=$Precision_{\mu}$,
                        ylabel=$Recall_{\mu}$,
                        samples=100]
                        \addplot[green, only marks, mark size=0.4] table {../data/fig/result/f2score.dat};
                        \addplot[gray, domain=0.021:1] {(4 * 0.1 * x) / (5 * x - 0.1)};
                        \addplot[gray, domain=0.041:1] {(4 * 0.2 * x) / (5 * x - 0.2)};
                        \addplot[gray, domain=0.061:1] {(4 * 0.3 * x) / (5 * x - 0.3)};
                        \addplot[gray, domain=0.081:1] {(4 * 0.4 * x) / (5 * x - 0.4)};
                        \addplot[gray, domain=0.101:1] {(4 * 0.5 * x) / (5 * x - 0.5)};
                        \addplot[gray, domain=0.121:1] {(4 * 0.6 * x) / (5 * x - 0.6)};
                        \addplot[gray, domain=0.141:1] {(4 * 0.7 * x) / (5 * x - 0.7)};
                        \addplot[gray, domain=0.17:1] {(4 * 0.8 * x) / (5 * x - 0.8)};
                        \addplot[gray, domain=0.19:1] {(4 * 0.9 * x) / (5 * x - 0.9)};
                        \coordinate (spypoint) at (axis cs:0.8413070951,0.654494382);
                        \coordinate (magnifyglass) at (axis cs:0.3,0.3);
                    \end{axis}
                    \spy [size=2.5cm] on (spypoint)
                        in node[fill=white] at (magnifyglass);
                \end{tikzpicture}
            }
        \end{tabular}
    \end{center}
    \caption{$Precision_{\mu}$ and $Recall_{\mu}$ of the top thousand simulations measured on the $F_{1}score_{\mu}$ for
    the left plot, $F_{\frac{1}{2}}score_{\mu}$ for the plot in the middle and $F_{2}score_{\mu}$ for the right plot.
    The magnifying glass is focusing on the best simulation measured on the underlying $F_{\beta}score_{\mu}$. The gray
    lines are illustrating the distribution of the underlying $F_{\beta}score_{\mu}$ in $\frac{1}{10}$ steps.}
    \label{fig:result}
\end{figure}

\input{experiment/results/influence_of_time_series_distance_measure.tex}
\input{experiment/results/influence_of_window_size_determination.tex}
\input{experiment/results/influence_of_threshold_determination.tex}
