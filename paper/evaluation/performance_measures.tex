\subsection{Performance Measures} \label{performance_measures}

All the various configured online gesture detection simulations are producing different results similar to figure
\ref{fig:experiment}. Every simulation yields in true positives ($tp$), true negatives ($tn$), false positives ($fp$)
and false negatives ($fn$) for every gesture class. Seen from this point of view, a simulation is a multi-class
classificator for the eight gesture classes. Common performance measures for multi-class classificators are
$Precision_{\mu}$, $Recall_{\mu}$ and $F_{\beta}score_{\mu}$ as mentioned in \cite{sokolova2009systematic}.

\begin{equation}
    Precision_{\mu} = \frac{\sum \limits_{i=1}^{l} tp_i}{\sum \limits_{i=1}^{l} (tp_i + fp_i)}
\end{equation}
\begin{equation}
    Recall_{\mu} = \frac{\sum \limits_{i=1}^{l} tp_i}{\sum \limits_{i=1}^{l} (tp_i + fn_i)}
\end{equation}
\begin{equation}
    F_{\beta}score_{\mu} = \frac{(\beta^2 + 1)Precision_{\mu} Recall_{\mu}}{\beta^2 Precision_{\mu} + Recall_{\mu}}
\end{equation}

Those multi-class performance measures provide the opportunity to compare and rank the results of all various configured
simulations. The main ranking measure used in this paper is the $F_{1}score_{\mu}$ that treats the influence of
$Precision_{\mu}$ and $Recall_{\mu}$ as coequal.
