%newpage
\section{Introduction} \label{introduction}

As time goes by things change, and those who understand change can adapt accordingly. This basic principle is also reflected in today's digital society, where sensor-equipped devices measure our environment and online algorithms process the generated data streams in quasi real-time to inform humans or cognitive systems about relevant trends and events that impact decision making.

Depending on the domain researchers either speak about events, patterns, or scenes that they aim to detect or recognize in time series, sensor, or data streams. Applications range from event detection for smart home control \cite{spiegel2015metering} over frequent pattern mining for engine optimization \cite{spiegel2015driving} to scene detection for video content \cite{acar2011mediaeval} and gesture recognition for human-computer interaction \cite{liu2009uwave}.

Commonly online algorithms for data streams employ the popular sliding window technique \cite{keogh2004sliding}, which observes the most recent sensor measurements and moves along the time axis as new measurements arrive. Usually each window is examined for a set of predefined events, which requires the comparison of the current time series segment and all preliminary learned instances of the relevant temporal patterns. In general, the pairwise dissimilarity comparisons of temporal patterns are performed by time series distance measures \cite{spiegel2015diss}.

The time and space complexity of the sliding window technique increases with decreasing step size as well as growing window size, measurement frequency, and number of preliminary learned instances. High computational demand and memory usage is especially problematic for embedded systems with only few resources \cite{kratz2011mobile,wilhelm2015ring}, which applies to the greatest part of sensor-equipped devices within the typical Internet of Things (IoT) scenario.

Our aim is to reduce the number of computational expensive dissimilarity comparisons that are required by the sliding window technique. To this end we propose a sliding window filter \cite{lesti2017filter}, which is able to decide whether the current window should be passed to a time series classifier or not. Although the filter could be considered as a binary classifier itself, it merely employs statistical measures with linear complexity and, thereby, avoids using computationally more expensive dissimilarity comparisons in many cases. Our approach to mitigate the computational complexity of event detection in data streams is different from other techniques in that we refrain from accelerating time series distance measures \cite{sart2010accelerating,spiegel2014lucky} or reducing dataset numerosity \cite{xi2006fast}.

We demonstrate the practical use of our proposed sliding window filter for gesture recognition in continuous streams of accelleration data \cite{lesti2017filter,liu2009uwave}, where a great amount of the necessary but expensive Dynamic Time Warping (DTW) distance calculations \cite{keogh2002exact} is replaced by less demanding statistical measures, such as the complexity estimate \cite{batista2011complexity} or sample variance \cite{chan1983algorithms}. Our experimental results show that the number of DTW distance calculations can be cut in half, while still maintaining the same high gesture recognition performance.

The rest of the paper is structured as follows. Chapter \ref{background_and_notation} introduces background and notation. Chapter \ref{filtering_approach} and \ref{evaluation} introduce and evaluate our proposed sliding window filter. We conclude with future work in Chapter \ref{conclusion_and_future_work}.


% The complexity estimate [1] (2.4) *
% The sample variance [2] (2.5) *
% Normalization [3] (2.2.2)
% Zscore [4] (2.2.2)
% Itakura Parallelogram [5]
% DTW distance [6] (2.2) *
% The experiment was inspired by [7] uWave (3.0), Furthermore the quantization proposed in [7] was applied. *
% Sakoe-Chiba Band [8] (2.2.1)
% DTW distance [9] (2.2) *
% Metric for multi-class classification [10] (3.3.3)
% Computational demand [11] (1.0) *
